{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e673581-1a03-4c78-871a-6cfa73584be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from hazm.sentence_tokenizer import SentenceTokenizer\n",
    "from hazm.word_tokenizer import WordTokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f7a83d-2b01-47b4-a41c-4abad01eb775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>fa_abs</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;\n",
       "پژوهش حاضر با…</td></tr><tr><td>&quot;پژوهش حاضر یک …</td></tr><tr><td>&quot;\n",
       "پژوهش حاضر، ب…</td></tr><tr><td>&quot;\n",
       "این پژوهش با …</td></tr><tr><td>&quot;\n",
       "این پژوهش با …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌───────────────────────────────────┐\n",
       "│ fa_abs                            │\n",
       "│ ---                               │\n",
       "│ str                               │\n",
       "╞═══════════════════════════════════╡\n",
       "│                                   │\n",
       "│ پژوهش حاضر با هدف بررسی رابطه ی…  │\n",
       "│ پژوهش حاضر یک پژوهش همبستگی و از… │\n",
       "│                                   │\n",
       "│ پژوهش حاضر، با هدف بررسی مدل مف…  │\n",
       "│                                   │\n",
       "│ این پژوهش با هدف پیش بینی سطوح …  │\n",
       "│                                   │\n",
       "│ این پژوهش با هدف تعیین سهم سبک …  │\n",
       "└───────────────────────────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_excel('fa_abs.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e780090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = SentenceTokenizer()\n",
    "\n",
    "df =df.with_columns([\n",
    "    pl.col('fa_abs').map_elements(\n",
    "        lambda x: sent_token.tokenize(x))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a459663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['پژوهش حاضر با هدف بررسی رابطه ی باورهای هوشی و ارتباط پدر- فرزند با انگیزه پیشرفت تحصیلی در دانش آموزان پسر مقطع متوسطه ی دوم شهرستان شوشتر در یک پژوهش هم بستگی انجام شد.',\n",
       " 'جامعه ی این پژوهش شامل کلیه ی دانش آموزان پسر مقطع متوسطه ی دوم شهرستان شوشتر در سال تحصیلی 97-96 بود.',\n",
       " '366 دانش آموز پسر بر اساس جدول نمونه گیری کرجسی و مورگان و با توجه به حجم جامعه (3323 نفر) به روش نمونه گیری تصادفی خوشه ای چندمرحله ای انتخاب شدند.',\n",
       " 'در این پژوهش دانش آموزان به پرسش نامه ی انگیزش پیشرفت (AMQ)، مقیاس نظریه تلویحی هوش (ITIS) و مقیاس ارتباط والد-فرزند (PCRI) پاسخ دادند.',\n",
       " 'تحلیل داده ها با استفاده از روش های آماری ضریب هم بستگی پیرسون و تحلیل رگرسیون چندگانه و نرم افزار آماری 22-SPSS انجام گرفت.',\n",
       " 'نتایج نشان داد که بین باور هوشی افزایشی و ارتباط پدر-فرزند با انگیزه پیشرفت تحصیلی در دانش آموزان رابطه ی مثبت و معناداری وجود دارد و بین باور هوشی ذاتی و انگیزه پیشرفت تحصیلی رابطه وجود ندارد.',\n",
       " 'همچنین، نتایج تحلیل رگرسیون نشان داد که از میان متغیرهای پیش بین باور هوشی افزایشی و ارتباط پدر- فرزند به طور معناداری انگیزه ی پیشرفت تحصیلی را در دانش آموزان پیش بینی می کنند براساس نتایج، می توان نتیجه گرفت دانش آموزانی که به منعطف و افزایشی بودن هوش باور و ارتباط نزدیکی با پدرشان دارند، انگیزه پیشرفت تحصیلی بیشتری نیز دارند اما دانش آموزانی که باور به ذاتی بودن هوش دارند، لزوما انگیزه پیشرفت تحصیلی بیشتری ندارند.',\n",
       " 'پژوهش حاضر یک پژوهش همبستگی و از نوع پژوهش های مدلسازی معادلات ساختاری بود.',\n",
       " 'هدف از این پژوهش بررسی برازش مدل علی حمایت های اجتماعی تحصیلی، مهارت های تحصیلی و خودکارآمدی تحصیلی بود.',\n",
       " 'جامعه آماری این پژوهش شامل تمامی دانش آموزان پایه دهم (اول متوسطه دوم) شهر شیراز بود که در سال تحصیلی 1399-1398 مشغول به تحصیل بودند.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "for row in df.iter_rows():\n",
    "    l = list(*row)\n",
    "    text += l\n",
    "text[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e7bf015-69e3-4d05-8995-f8917b16a961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['پژوهش', 'حاضر', 'با', 'هدف', 'بررسی', 'رابطه', 'ی', 'باورهای', 'هوشی', 'و', 'ارتباط', 'پدر-', 'فرزند', 'با', 'انگیزه', 'پیشرفت', 'تحصیلی', 'در', 'دانش', 'آموزان', 'پسر', 'مقطع', 'متوسطه', 'ی', 'دوم', 'شهرستان', 'شوشتر', 'در', 'یک', 'پژوهش', 'هم', 'بستگی', 'انجام', 'شد', '.', 'جامعه', 'ی', 'این', 'پژوهش', 'شامل', 'کلیه', 'ی', 'دانش', 'آموزان', 'پسر', 'مقطع', 'متوسطه', 'ی', 'دوم', 'شهرستان']\n"
     ]
    }
   ],
   "source": [
    "#splitting the punctuations from tokens\n",
    "punc = '?!./,;:\"()'\n",
    "tokenizer = WordTokenizer()\n",
    "segments = []\n",
    "for sent in text:\n",
    "    for token in tokenizer.tokenize(sent):\n",
    "        segments_temp = []\n",
    "        for char in token:\n",
    "            if char in punc:\n",
    "                segments_temp.append(char)\n",
    "                continue\n",
    "            if not segments_temp:\n",
    "                segments_temp.append(char)\n",
    "                continue\n",
    "            if segments_temp[-1] not in punc:\n",
    "                segments_temp[-1] += char\n",
    "            else:\n",
    "                segments_temp.append(char)\n",
    "        for seg in segments_temp:\n",
    "            if not any(x in seg for x in '#$%&*123456789ACDVRPXW'):\n",
    "                segments.append(seg)\n",
    "\n",
    "print(segments[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbeedce2-81b9-421a-8168-84ed6d155d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', \"'\", '(', ')', '+', '+Imp', ',', '-', '-=', '-=B', '-=ES', '-=d', '-=r', '-=ß', '-=β', '-=\\u200fβ', '-B', '-BF', '-FFI', '-GHQ', '-GSE', '-ISI', '-Imp', '-Lisrel', '-NEO-FFI', '-SF', '-Spss', '-back', '-p=', '-r', '-r=', '-\\xa0', '-\\xa0آدم', '-\\xa0درخت', '-آزمایش', '-آزمایشی', '-آزمون', '-آموزان', '-آگاهی', '-اجبار', '-از', '-است', '-استراتژی', '-استقلال', '-اصلاح', '-اضطراب-', '-البته', '-انگیزشی', '-اهمیت']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(segments))+['<s>', '</s>']\n",
    "vocab.sort()\n",
    "print(vocab[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003e8f0c-19c1-479c-98f8-1fe5868155f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<s>', '<s>', 'پژوهش', 'حاضر', 'با', 'هدف', 'بررسی', 'رابطه', 'ی', 'باورهای', 'هوشی', 'و', 'ارتباط', 'پدر-', 'فرزند', 'با', 'انگیزه', 'پیشرفت', 'تحصیلی', 'در', 'دانش', 'آموزان', 'پسر', 'مقطع', 'متوسطه', 'ی', 'دوم', 'شهرستان', 'شوشتر', 'در', 'یک', 'پژوهش', 'هم', 'بستگی', 'انجام', 'شد', '.', '</s>', '</s>', '</s>', '<s>', '<s>', '<s>', 'جامعه', 'ی', 'این', 'پژوهش', 'شامل', 'کلیه', 'ی', 'دانش', 'آموزان', 'پسر', 'مقطع', 'متوسطه', 'ی', 'دوم', 'شهرستان', 'شوشتر', 'در', 'سال', 'تحصیلی', '-', 'بود', '.', '</s>', '</s>', '</s>', '<s>', '<s>', '<s>', 'دانش', 'آموز', 'پسر', 'بر', 'اساس', 'جدول', 'نمونه', 'گیری', 'کرجسی', 'و', 'مورگان', 'و', 'با', 'توجه', 'به', 'حجم', 'جامعه', '(', 'نفر', ')', 'به', 'روش', 'نمونه', 'گیری', 'تصادفی', 'خوشه', 'ای', 'چندمرحله', 'ای', 'انتخاب', 'شدند', '.', '</s>', '</s>', '</s>', '<s>', '<s>', '<s>', 'در', 'این', 'پژوهش', 'دانش', 'آموزان', 'به', 'پرسش', 'نامه', 'ی', 'انگیزش', 'پیشرفت', '(', ')', '،', 'مقیاس', 'نظریه', 'تلویحی', 'هوش', '(', 'ITIS', ')', 'و', 'مقیاس', 'ارتباط', 'والد-فرزند', '(', ')', 'پاسخ', 'دادند', '.', '</s>', '</s>', '</s>', '<s>', '<s>', '<s>', 'تحلیل', 'داده', 'ها', 'با']\n"
     ]
    }
   ],
   "source": [
    "#inserting sentence start and end paddings naively just looking at dots\n",
    "def padding(segments: list[str] , n: int) -> list[str]:\n",
    "    start_of_sentence = True\n",
    "    with_padding = []\n",
    "    for token in segments:\n",
    "        if start_of_sentence:\n",
    "            for i in range(n-1):\n",
    "                with_padding.append('<s>')\n",
    "            start_of_sentence = False\n",
    "        with_padding.append(token)\n",
    "        if token == \".\" :\n",
    "            for i in range(n-1):\n",
    "                with_padding.append('</s>')\n",
    "            start_of_sentence = True\n",
    "    return with_padding\n",
    "\n",
    "print(padding(segments , 4)[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c16012ca-150f-40ac-b21a-f154dd562ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', '<s>', 'پژوهش'), ('<s>', 'پژوهش', 'حاضر'), ('پژوهش', 'حاضر', 'با'), ('حاضر', 'با', 'هدف'), ('با', 'هدف', 'بررسی'), ('هدف', 'بررسی', 'رابطه'), ('بررسی', 'رابطه', 'ی'), ('رابطه', 'ی', 'باورهای'), ('ی', 'باورهای', 'هوشی'), ('باورهای', 'هوشی', 'و'), ('هوشی', 'و', 'ارتباط'), ('و', 'ارتباط', 'پدر-'), ('ارتباط', 'پدر-', 'فرزند'), ('پدر-', 'فرزند', 'با'), ('فرزند', 'با', 'انگیزه'), ('با', 'انگیزه', 'پیشرفت'), ('انگیزه', 'پیشرفت', 'تحصیلی'), ('پیشرفت', 'تحصیلی', 'در'), ('تحصیلی', 'در', 'دانش'), ('در', 'دانش', 'آموزان'), ('دانش', 'آموزان', 'پسر'), ('آموزان', 'پسر', 'مقطع'), ('پسر', 'مقطع', 'متوسطه'), ('مقطع', 'متوسطه', 'ی'), ('متوسطه', 'ی', 'دوم'), ('ی', 'دوم', 'شهرستان'), ('دوم', 'شهرستان', 'شوشتر'), ('شهرستان', 'شوشتر', 'در'), ('شوشتر', 'در', 'یک'), ('در', 'یک', 'پژوهش')]\n"
     ]
    }
   ],
   "source": [
    "#making a function that produces ngrams given n\n",
    "def ngram(segments: list[str] , n: int) -> list[tuple]:\n",
    "    seg = padding(segments , n)\n",
    "    ngrams = []\n",
    "    i = 0\n",
    "    while i < (len(seg)-n):\n",
    "        ngrams.append(tuple(seg[i:i+n]))\n",
    "        i += 1\n",
    "    return ngrams\n",
    "print(ngram(segments , 3)[:30])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "650b565a-962b-4752-94e3-3a3fd4a8825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '<s>', 'پژوهش') 2198\n",
      "('<s>', 'پژوهش', 'حاضر') 1879\n",
      "('پژوهش', 'حاضر', 'با') 1472\n",
      "('حاضر', 'با', 'هدف') 1582\n",
      "('با', 'هدف', 'بررسی') 1045\n",
      "('هدف', 'بررسی', 'رابطه') 185\n",
      "('بررسی', 'رابطه', 'ی') 50\n",
      "('رابطه', 'ی', 'باورهای') 4\n",
      "('ی', 'باورهای', 'هوشی') 1\n",
      "('باورهای', 'هوشی', 'و') 14\n"
     ]
    }
   ],
   "source": [
    "def gram_counts(segments: list[str] , n: int) -> dict[str: int]:\n",
    "    count_dict = {}\n",
    "    \n",
    "    for gram in ngram(segments , n):\n",
    "        if gram in count_dict:\n",
    "            count_dict[gram] += 1\n",
    "        else:\n",
    "            count_dict[gram] = 1\n",
    "    if n > 1:        \n",
    "        for gram in ngram(segments , n-1):\n",
    "            if gram in count_dict:\n",
    "                count_dict[gram] += 1\n",
    "            else:\n",
    "                count_dict[gram] = 1\n",
    "    return count_dict\n",
    "    \n",
    "counts = gram_counts(segments , 3)\n",
    "n = 0\n",
    "for i in counts.__iter__():\n",
    "    n += 1 \n",
    "    if n > 10:\n",
    "        break\n",
    "    print(i , counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a33fd94-4aa5-46b7-a902-8a58b4b59ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prob_gen():\n",
    "    \n",
    "    def __init__(self, segments: str , n: int):\n",
    "        self.counts = gram_counts(segments , n)\n",
    "        self.n = n\n",
    "\n",
    "    def gramProb(self , gram: tuple):\n",
    "        try:\n",
    "            return self.counts[gram]/self.counts[tuple(gram[0:-1])]\n",
    "        except:\n",
    "            return 0.001\n",
    "    \n",
    "    def sentProbs(self , sentence: list[str]):\n",
    "        prob = []\n",
    "        for i in range(len(sentence)-self.n+1):\n",
    "            prob.append(self.gramProb(tuple(sentence[i:i+self.n])))\n",
    "        return prob   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a0bb648-4579-4c39-bfec-0f78271cce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total segments:  1493204\n",
      "train 80% : 1194563\n",
      "dev 10% : 1194563 : 1343883\n",
      "test 10% : 1343883 :\n"
     ]
    }
   ],
   "source": [
    "print('total segments: ' ,len(segments))\n",
    "train = len(segments)*80//100\n",
    "print('train 80% :' , train)\n",
    "test = len(segments)*90//100\n",
    "print('dev 10% :' , train, ':' , test)\n",
    "print('test 10% :' , len(segments)*90//100, ':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4844539-77fd-4597-9e6b-cfd44590b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "probgen = Prob_gen(segments[:train] , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6903c130-4369-4b39-bb1a-83b7fbf54b52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Prob_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperplexity\u001b[39m(probgen: \u001b[43mProb_generator\u001b[49m , test_set: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mprod([(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mp)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_set)) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m probgen\u001b[38;5;241m.\u001b[39msentProbs(test_set)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Prob_generator' is not defined"
     ]
    }
   ],
   "source": [
    "def perplexity(probgen: Prob_gen , test_set: list[str]):\n",
    "    return np.prod([(1/p)**(1/len(test_set)) for p in probgen.sentProbs(test_set)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30263606-4ac0-4949-bf8b-292192a86f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"grams     peplexity\")\n",
    "for i in range(1,7):\n",
    "    probgen = Prob_gen(segments[:train] , i)\n",
    "    print(i , '       ' , round(perplexity(probgen , segments[train:test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ebf52-baa6-4c2e-98a1-fbc919bc7f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probgen = Prob_gen(segments[:train] , 2)\n",
    "perplexity(probgen , segments[test:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea289e-fcad-45ea-aeed-184bb1e2cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_gen(sentence_count: int):\n",
    "    init = ['<s>']\n",
    "    for i in range(10):\n",
    "        temp_dict = {}\n",
    "        for gram in probgen.counts:\n",
    "            if init[-1] == gram[0]:\n",
    "                temp_dict.update({gram[1]:})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afdd96f0-b643-4499-b07e-e69a715600e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9296142-8c1d-427b-8ced-59df2a394ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
